{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df1fdbef",
   "metadata": {},
   "source": [
    "# TIM - TP 7 : Détections de coins\n",
    "\n",
    "Aujourd'hui, on va s'intéresser à plusieurs algorithmes permettant de faire de la détection de coins. Un coin est une catégorie de points d'intérêts, c'est-à-dire un point d'une image avec une caractéristique spécifique, qui peut ensuite être utiliser dans plusieurs tâches, comme du pattern matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70def8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Chargement des librairies\n",
    "...\n",
    "\n",
    "# Définition du chemin de la base de données des images\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1fe77",
   "metadata": {},
   "source": [
    "## Ex. 1 : Détecteur de coins d'Harris\n",
    "\n",
    "Commençons par un classique : le détecteur de coin d'Harris. Cet algorithme permet de détecter donc des coins, à savoir des grandes variations d'intensités locales dans toutes les directions. \n",
    "\n",
    "---\n",
    "#### Description mathématique de l'opérateur\n",
    "\n",
    "L'idée est de considérer un voisinage centré autour d'un pixel, de le décaler légèrement dans plusieurs directions, et de calculer pour chaque déplacement la variation d'intensité. Cela se traduit mathématiquement par la fonction suivante :\n",
    "\n",
    "\\begin{equation*}\n",
    "    E(u,v) = \\sum_{x,y} W(x,y) \\cdot [I(x+u,y+v) - I(x,y)]²\n",
    "\\end{equation*}\n",
    "\n",
    "Dans cette équation:\n",
    "- $I(x,y)$ correspond à l'intensité de l'image\n",
    "- $(u,v)$ est un petit déplacement\n",
    "- $W(x,y)$ est une fenêtre gaussienne locale centrée en $(x,y)$\n",
    "\n",
    "$E(u,v)$ représente donc la différence d'intensité de $I$ dans une direction $(u,v)$. De ce fait:\n",
    "- Si $E(u,v)$ est faible dans toutes les directions, la région est plate\n",
    "- Si $E(u,v)$ est fort dans une seule direction, on a un bord\n",
    "- Si $E(u,v)$ est fort dans toutes les directions, on a un coin\n",
    "\n",
    "Grâce à une approximation du premier ordre de Taylor, on peut linéariser $I(x+u,y+v)$ pour des petits déplacements: \n",
    "\n",
    "\\begin{equation*}\n",
    "    I(x+u,y+v) \\approx I(x,y) + I_x(x,y) \\cdot u + I_y(x,y) \\cdot v\n",
    "\\end{equation*}\n",
    "\n",
    "Et donc :\n",
    "\n",
    "\\begin{equation*}\n",
    "    E(u,v) \\approx \\sum_{x,y} W(x,y) \\cdot [I_x u - I_y v]²\n",
    "\\end{equation*}\n",
    "\n",
    "En développant le carré : \n",
    "\n",
    "\\begin{equation*}\n",
    "    E(u,v) \\approx \\sum_{x,y} W(x,y) \\cdot (I_x² u² + 2 I_x I_y u v + I_y² v²)\n",
    "\\end{equation*}\n",
    "\n",
    "On écrit sous forme matricielle :\n",
    "\n",
    "\\begin{equation*}\n",
    "    E(u,v) \\approx \\begin{bmatrix} u & v \\end{bmatrix} M \\begin{bmatrix} u \\\\ v \\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Avec $M$ la matrice des moments du gradient:\n",
    "\n",
    "\\begin{equation*}\n",
    "    M(x,y) =  \\sum_{x,y} W(x,y)  \\begin{bmatrix}\n",
    "                I_{x}² & I_x I_y \\\\\n",
    "                I_x I_y & I_{y}²\n",
    "                \\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Maintenant, interprétons $M$. C'est une matrice symétrique $2 \\times 2$, donc elle a deux valeurs propres réelles positives $\\lambda_1$ et $\\lambda_2$. On peut donc réecrire l'équation de cette manière : \n",
    "\n",
    "\\begin{equation*}\n",
    "    E(u,v) \\approx \\lambda_1 a_1² + \\lambda_2 a_2²\n",
    "\\end{equation*}\n",
    "\n",
    "Où a_1 et a_2 sont les composantes de $(u,v)$ dans la base propre de $M$. De ce fait :\n",
    "- Si les deux $\\lambda$ sont petits, $E(u,v)$ varie peu et donc on est en région plate\n",
    "- Si un seul $\\lambda$ est grand, $E(u,v)$ varie dans une seule direction, et donc on est sur un bord\n",
    "- Si les deux $\\lambda$ sont grands, $E(u,v)$ varie dans toutes les directions, et donc on a un coin.\n",
    "\n",
    "Cependant, calculer $\\lambda_1$ et $\\lambda_2$ sur toute l'image est coûteux. Harris propose donc pour cela un critère scalaire approché, appelé critère de Harris :\n",
    "\n",
    "\\begin{equation*}\n",
    "    R = det(M) - k(trace(M))²\n",
    "\\end{equation*}\n",
    "\n",
    "Avec :\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "        det(M) = \\lambda_1 \\lambda_2 \\\\\n",
    "        trace(M) = \\lambda_1 + \\lambda_2\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "Et $k$ est un paramètre empirique (souvent entre 0.04 et 0.06). En remplaçant les $\\lambda$ par les termes de $M$, on obtient l'équation finale du critère de Harris :\n",
    "\n",
    "\\begin{equation*}\n",
    "    R = (S_{xx} S_{yy} - S_{xy}²) - k (S_{xx} + S_{yy})²\n",
    "\\end{equation*}\n",
    "\n",
    "Avec $S_{xx} = G \\ast I_x²$, $S_{xy} = G \\ast (I_x I_y)$ et $S_{yy} = G \\ast I_y²$. $G$ correspond à un filtre gaussien pour lisser les produits de gradients, afin de stabiliser la détection face au bruit et donner plus de poids au centre de la fenêtre.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d128f",
   "metadata": {},
   "source": [
    "On va recoder l'algorithme en entier, même s'il existe évidemment une implémentation d'OpenCV. Commençons d'abord par charger l'image exemple du jour : *blox.jpg*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd147d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Chargement de l'image et affichage\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25ef77",
   "metadata": {},
   "source": [
    "La première étape consiste à lisser l'image pour éviter que le bruit local puisse être considéré comme un contour. Appliquez donc un filtre gaussien 3x3 sur l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Filtrage Gaussien 3X3 pour lisser l'image\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7d4c6",
   "metadata": {},
   "source": [
    "La détection de coins se basent sur des contours. Pour cela, Harris se base sur les gradients directionnels $I_x$ et $I_y$. Il y'a plusieurs possibilités ici, mais disons que les filtres de Sobel sont les plus couramment utilisés... Donc on va faire pareil. \n",
    "\n",
    "Extrayez les gradients directionnels $I_x$ et $I_y$ via des filtres de Sobel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83240779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Extraction et affichage des gradients directionnels Ix et Iy via des filtres de Sobel\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3379c",
   "metadata": {},
   "source": [
    "On va maintenant calculer comme expliqué précédemment $S_{xx}$, $S_{xy}$ et $S_{yy}$. Le noyau gaussien à appliquer $G$ est de taille $blocksize \\times blocksize$ (variable qui sera en paramètre de l'algorithme).\n",
    "\n",
    "Construisez $S_{xx}$, $S_{xy}$ et $S_{yy}$ et affichez les produits de gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd56a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Construction et affichage de Sxx, Sxy et Syy\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92829ad8",
   "metadata": {},
   "source": [
    "On va maintenant calculer directement le critère de Harris :\n",
    "\n",
    "\\begin{equation*}\n",
    "    R(x,y) = (S_{xx} S_{yy} - S_{xy}²) - k (S_{xx} + S_{yy})²\n",
    "\\end{equation*}\n",
    "\n",
    "$k$ est en paramètre de la fonction.\n",
    "\n",
    "Calculez $R(x,y)$ et affichez le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd19a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Calcul et affichage de R(x,y)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b37c46",
   "metadata": {},
   "source": [
    "**_QUESTION :_** Comment interpréter les valeurs de $R(x,y)$ (c'est-à-dire les pixels blancs/noirs/gris)? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1593e06",
   "metadata": {},
   "source": [
    "**_REPONSE :_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9817ad",
   "metadata": {},
   "source": [
    "Il est temps de sélectionner uniquement les pixels candidats à être des coins, donc les fortes valeurs positives. Pour cela, on va simplement faire une binarisation à un seuil $\\tau = \\alpha \\cdot max(R)$. Ici, on va prendre $\\alpha$ à 0.01, mais il sera un paramètre dans la fonction globale.\n",
    "\n",
    "Faites la binarisation et visualisez le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7cc03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Binarisation pour sélectionner les pixels candidats à être des coins et affichage du résultat\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f785ae9",
   "metadata": {},
   "source": [
    "Bon, la visualisation de pixels noirs et blancs peut ne pas être très pertinent... Créez une visualisation de l'image originale avec un cercle rouge dessiné autour de chaque pixel candidat.\n",
    "\n",
    "*Note : votre image noir et blanc doit évidemment être convertie en couleur pour une telle visualisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938932db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Visualisation des pixels candidats sur l'image originale\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11e43e",
   "metadata": {},
   "source": [
    "**_QUESTION :_** Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702cc6a2",
   "metadata": {},
   "source": [
    "**_REPONSE :_** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267412f",
   "metadata": {},
   "source": [
    "Une dernière étape est nécessaire en post-traitement : la Non-Maximum Suppression (NMS). C'est un algorithme de post-traitement très largement utilisé (même en Deep Learning !), permettant d'éliminer les détections multiples d'un même coin dans notre cas. \n",
    "\n",
    "Le principe qu'on va utiliser ici est ce qu'on appelle un Greedy NMS. On récupère tous les coordonnées des pixels candidats $(x_c, y_c)$ et leurs scores $s_c = R(x_c,y_c)$. On trie ensuite chaque pixel candidat $(x_c, y_c, s_c)$ dans l'ordre décroissant de score, considérant qu'un pixel est plus probablement un coin si son score est gros. \n",
    "\n",
    "Puis, on crée une matrice de booléens $allow$ de la taille de $R(x,y)$ initialisé à True partout. On parcourt chacun des candidats dans la liste triée et on regarde la valeur de $allow$ aux coordonnées du pixel candidat :\n",
    "- Si $R(x_c,y_c)$ = True, alors le pixel est retenu, et la fenêtre carrée de taille $(2 \\times min\\_distance + 1 , 2 \\times min\\_distance + 1)$ centrée sur $(x_c,y_c)$ de $allow$ passe à False\n",
    "- Si $R(x_c,y_c)$ = False, alors le pixel est éliminé\n",
    "\n",
    "La fonction retourne les positions $(x_c, y_c)$ des pixels retenus. $min\\_distance$ est un paramètre qui sera défini dans la fonction globale.\n",
    "\n",
    "A vous de jouer, et codez la fonction de Non-Maximum Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Non-maximum Suppression\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dadbfc",
   "metadata": {},
   "source": [
    "Appliquez maintenant le NMS sur vos résultats précédents, et affichez l'image avec les coins détectés restants entourés en rouge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Post-traitement NMS et affichage des coins détectés restants\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332288c",
   "metadata": {},
   "source": [
    "**_QUESTION :_** Alors, le résultat est-il meilleur ? Votre algorithme répond-il totalement aux attentes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e6d65",
   "metadata": {},
   "source": [
    "**_REPONSE :_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fdf0cd",
   "metadata": {},
   "source": [
    "Regroupez tout votre code dans une fonction pour la détection de coins d'Harris. Mettez bien certaines variables en paramètres (déjà évoqué précédemment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Fonction de détection de coins d'Harris\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec8db7",
   "metadata": {},
   "source": [
    "Bravo, ce n'était pas facile, mais vous avez réussi à coder le détecteur de coins d'Harris ! On va maintenant voir comment le faire avec OpenCV. \n",
    "\n",
    "OpenCV propose 2 méthodes pour appliquer Harris :\n",
    "- *cv2.cornerHarris*, qui renvoit la carte $R(x,y)$ comme effectué précédemment, et sans post-traitement (NMS)\n",
    "- *cv2.goodFeaturesToTrack* avec l'option *useHarrisDetector=True*, qui performe Harris avec un post-traitement NMS et renvoie les coordonnées des coins.\n",
    "\n",
    "On pourrait comparer les cartes $R(x,y)$ produites par votre algorithme et celui d'OpenCV, mais bon, on va plutôt directement utiliser *goodFeaturesToTrack*. \n",
    "\n",
    "Faites une détection de coins d'Harris avec cette fonction d'OpenCV et visualisez le résultat. A vous de trouver des paramètres adéquats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Détection de coins d'Harris via cv2.goodFeaturesToTrack\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c7ef9",
   "metadata": {},
   "source": [
    "## Ex. 2 : Détecteurs de coins de Shi-Tomasi\n",
    "\n",
    "Un deuxième algorithme pour la détection de coins : Shi-Tomasi. Rassurez-vous, ça va être plus rapide que pour l'exercice précédent, puisque Shi-Tomasi repose sur le même principe que Harris.\n",
    "\n",
    "Pour rappel, avec Harris, on calculait le critère de Harris, de la forme suivante : \n",
    "\n",
    "\\begin{equation*}\n",
    "    R = det(M) - k(trace(M))²\n",
    "\\end{equation*}\n",
    "\n",
    "Avec :\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "        det(M) = \\lambda_1 \\lambda_2 = S_{xx} + S_{yy} \\\\\n",
    "        trace(M) = \\lambda_1 + \\lambda_2 = S_{xx} S_{yy} - S_{xy}²\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "Shi-Tomasi lui définit le score suivant :\n",
    "\n",
    "\\begin{equation*}\n",
    "    score(x,y) = min(\\lambda_1, \\lambda_2)\n",
    "\\end{equation*}\n",
    "\n",
    "Un coin est alors détecté si ce score dépasse un seuil prédéfini. \n",
    "\n",
    "Pour éviter une diagonalisation de $M$ pour trouver les valeurs propres, on calcule les valeurs propres à partir de $det(M)$ et $trace(M)$ :\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\lambda_{1,2} = \\frac{trace(M) \\pm \\sqrt{trace(M)² - 4 \\cdot det(M)}}{2}\n",
    "\\end{equation*}\n",
    "\n",
    "Ici, on a besoin uniquement du minimum entre $\\lambda_1$ et $\\lambda_2$ :\n",
    "\n",
    "\\begin{equation*}\n",
    "    min(\\lambda_1,\\lambda_2) = \\frac{trace(M) - \\sqrt{trace(M)² - 4 \\cdot det(M)}}{2}\n",
    "\\end{equation*}\n",
    "\n",
    "De ce fait, à la place de la carte $R(x,y)$ pour Harris, Shi-Tomasi calcule la carte $\\lambda_{min}$ en suivant l'équation ci-dessus (pour chaque pixel)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc95a6",
   "metadata": {},
   "source": [
    "Modifiez la fonction de détection d'Harris pour effectuer une détection de coins de Shi-Tomasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Fonction de détections de coins de Shi-Tomasi\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce63f0b",
   "metadata": {},
   "source": [
    "Appliquez votre algorithme sur l'image du jour et visualisez le résultat (avec les coins détectés entourés en rouge). Ajustez les paramètres afin d'obtenir le meilleur résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fca44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Application de Shi-Tomasi et visualisation des résultats\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059296e",
   "metadata": {},
   "source": [
    "**_QUESTION :_** Obtenez-vous un meilleur résultat qu'avec le détecteur d'Harris ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4835ca05",
   "metadata": {},
   "source": [
    "**_REPONSE :_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2418273",
   "metadata": {},
   "source": [
    "Tout comme Harris, OpenCV propose deux implémentations de Shi-Tomasi :\n",
    "- *cv2.cornerMinEigenVal*, qui renvoit la carte $\\lambda_{min}$ sans post-processing NMS\n",
    "- *cv2.goodFeaturesToTrack*, qui par défaut (*useHarrisDetector=False*), utilise Shi-Tomasi avec un post-processing NMS.\n",
    "\n",
    "Effectuez une détection de Shi-Tomasi avec OpenCV et affichez le résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Shi-Tomasi via OpenCV et visualisation du résultat\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86adbf69",
   "metadata": {},
   "source": [
    "Pour finir avec les détections de coins, on applique souvent en post-processing un algorithme permettant d'améliorer la localisation des coins détectés. L'algorithme étant un peu complexe, on va uniquement utiliser la fonction fournie par OpenCV : *cv2.cornerSubPix()*.\n",
    "\n",
    "Améliorez vos résultats précédants (Harris et Shi-Tomasi) en appliquant *cv2.cornerSubPix* et visualisez les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1628210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "# Post-traitement cornerSubPix sur les coins détectés (Harris et Shi-Tomasi) et visualisation des résultats\n",
    "...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
